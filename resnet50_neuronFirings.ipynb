{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Input, Flatten, Dropout, UpSampling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from IPython.display import Image, display\n",
    "import random, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import cv2\n",
    "import glob\n",
    "import keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dir = './data/cifar100/images/'\n",
    "annotation_dir = './data/cifar100/meta/'\n",
    "test_path = './data/cifar100/meta/test.txt'\n",
    "train_path = './data/cifar100/meta/train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, mode='r') as f:\n",
    "    f_lines = f.readlines()\n",
    "    classes = set([s.split('/')[0] for s in f_lines])\n",
    "    classes = sorted(list(classes))\n",
    "    test_annotations = {food_class:[] for food_class in classes}\n",
    "    for s in f_lines:\n",
    "        food_class, f_num = s.rstrip('\\n').split('/')\n",
    "        test_annotations[food_class].append(f_num)\n",
    "\n",
    "with open(train_path, mode='r') as f:\n",
    "    train_annotations = {food_class:[] for food_class in classes}\n",
    "    for s in f.readlines():\n",
    "        food_class, f_num = s.rstrip('\\n').split('/')\n",
    "        train_annotations[food_class].append(f_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './data/cifar100/test/'\n",
    "for i in classes:\n",
    "    os.mkdir(f_path+i)\n",
    "train_dir = './data/cifar100/train/'\n",
    "for i in classes:\n",
    "    os.mkdir(f_path+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データセット生成\n",
    "for img_class, img_list in train_annotations.items():\n",
    "    imgsrc_name = [x_dir+img_class+'/'+img_num+'.jpg' for img_num in img_list]\n",
    "    imgsrc_list = [cv2.imread(i) for i in imgsrc_name]\n",
    "    for i in range(len(imgsrc_list)):\n",
    "        img = imgsrc_list[i]\n",
    "        img_src = imgsrc_name[i]\n",
    "        if img.shape[0] > img.shape[1]:\n",
    "            h_len = img.shape[1]\n",
    "            h_center = int(img.shape[0]/2)\n",
    "            temp_img = img[int(h_center-(h_len/2)): int(h_center+(h_len/2)), 0: img.shape[1]]\n",
    "            temp_img = cv2.resize(temp_img, dsize=(300, 300))\n",
    "        else:\n",
    "            v_len = img.shape[0]\n",
    "            v_center = int(img.shape[1]/2)\n",
    "            temp_img = img[0: img.shape[0], int(v_center-(v_len/2)): int(v_center+(v_len/2))]\n",
    "            temp_img = cv2.resize(temp_img, dsize=(300, 300))\n",
    "        w_path = train_dir + img_class + \"/\" + img_src.split('/')[-1]\n",
    "        cv2.imwrite(w_path, temp_img)\n",
    "\n",
    "for img_class, img_list in test_annotations.items():\n",
    "    imgsrc_name = [x_dir+img_class+'/'+img_num+'.jpg' for img_num in img_list]\n",
    "    imgsrc_list = [cv2.imread(i) for i in imgsrc_name]\n",
    "    for i in range(len(imgsrc_list)):\n",
    "        img = imgsrc_list[i]\n",
    "        img_src = imgsrc_name[i]\n",
    "        if img.shape[0] > img.shape[1]:\n",
    "            h_len = img.shape[1]\n",
    "            h_center = int(img.shape[0]/2)\n",
    "            temp_img = img[int(h_center-(h_len/2)): int(h_center+(h_len/2)), 0: img.shape[1]]\n",
    "            temp_img = cv2.resize(temp_img, dsize=(300, 300))\n",
    "        else:\n",
    "            v_len = img.shape[0]\n",
    "            v_center = int(img.shape[1]/2)\n",
    "            temp_img = img[0: img.shape[0], int(v_center-(v_len/2)): int(v_center+(v_len/2))]\n",
    "            temp_img = cv2.resize(temp_img, dsize=(300, 300))\n",
    "        w_path = test_dir + img_class + \"/\" + img_src.split('/')[-1]\n",
    "        cv2.imwrite(w_path, temp_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = len(classes)\n",
    "train_dir = './data/cifar100/train/'\n",
    "test_dir = './data/cifar100/test/'\n",
    "nb_train_samples = 50000\n",
    "nb_validation_samples = 10000\n",
    "img_width, img_height = 32, 32\n",
    "batch_size = 32\n",
    "nb_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91750 images belonging to 101 classes.\n",
      "Found 25250 images belonging to 101 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255, zoom_range=0.2, horizontal_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_dir,\n",
    "  target_size=(img_width, img_height),\n",
    "  color_mode='rgb',\n",
    "  classes=classes,\n",
    "  class_mode='categorical',\n",
    "  batch_size=16)\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "  test_dir,\n",
    "  target_size=(img_width, img_height),\n",
    "  color_mode='rgb',\n",
    "  classes=classes,\n",
    "  class_mode='categorical',\n",
    "  batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2867/2867 [==============================] - 15542s 5s/step - loss: 3.3622 - accuracy: 0.2785 - val_loss: 1.8475 - val_accuracy: 0.5317\n",
      "Epoch 2/15\n",
      "2867/2867 [==============================] - 17854s 6s/step - loss: 1.7423 - accuracy: 0.5627 - val_loss: 1.3035 - val_accuracy: 0.6599\n",
      "Epoch 3/15\n",
      "2454/2867 [========================>.....] - ETA: 36:59 - loss: 1.3277 - accuracy: 0.6605"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867/2867 [==============================] - 18104s 6s/step - loss: 1.0795 - accuracy: 0.7193 - val_loss: 0.9328 - val_accuracy: 0.7482\n",
      "Epoch 5/15\n",
      "2867/2867 [==============================] - 18618s 6s/step - loss: 0.8979 - accuracy: 0.7633 - val_loss: 0.8536 - val_accuracy: 0.7718\n",
      "Epoch 6/15\n",
      "2867/2867 [==============================] - 18737s 7s/step - loss: 0.7698 - accuracy: 0.7965 - val_loss: 0.8145 - val_accuracy: 0.7820\n",
      "Epoch 7/15\n",
      "2129/2867 [=====================>........] - ETA: 1:11:38 - loss: 0.6550 - accuracy: 0.8257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867/2867 [==============================] - 18657s 7s/step - loss: 0.6634 - accuracy: 0.8224 - val_loss: 0.8327 - val_accuracy: 0.7828\n",
      "Epoch 8/15\n",
      "2785/2867 [============================>.] - ETA: 8:01 - loss: 0.5684 - accuracy: 0.8455"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867/2867 [==============================] - 18819s 7s/step - loss: 0.4949 - accuracy: 0.8660 - val_loss: 0.6249 - val_accuracy: 0.8386\n",
      "Epoch 10/15\n",
      "1416/2867 [=============>................] - ETA: 2:21:32 - loss: 0.4189 - accuracy: 0.8833"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2867/2867 [==============================] - 18350s 6s/step - loss: 0.4368 - accuracy: 0.8780 - val_loss: 0.6673 - val_accuracy: 0.8363\n",
      "Epoch 11/15\n",
      "2867/2867 [==============================] - 19173s 7s/step - loss: 0.3840 - accuracy: 0.8916 - val_loss: 0.8050 - val_accuracy: 0.8093\n",
      "Epoch 12/15\n",
      " 623/2867 [=====>........................] - ETA: 3:13:14 - loss: 0.3002 - accuracy: 0.9157"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(img_width, img_height, 3))\n",
    "ResNet50 = ResNet50(include_top=False, weights='imagenet',input_tensor=input_tensor)\n",
    " \n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=ResNet50.output_shape[1:]))\n",
    "top_model.add(Dense(nb_classes, activation='softmax'))\n",
    " \n",
    "input_arg = ResNet50.input\n",
    "model = Model(inputs=input_arg, outputs=top_model(ResNet50.output))\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-3, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,\n",
    "    epochs=nb_epoch,\n",
    "    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./models/cifar100/resnet50_pretrained_iter15.pth\"\n",
    "model.save(PATH)\n",
    "model = keras.models.load_model(PATH, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予測結果\n",
    "#y_predはiter4回，y_pred_5はiter5回\n",
    "img_path = './data/cifar100/test/*'\n",
    "img_dir = glob.glob(img_path)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for class_dir in sorted(img_dir):\n",
    "    class_images = glob.glob(class_dir+\"/*\")\n",
    "    for img_data in class_images:\n",
    "        img = image.load_img(img_data, target_size=(img_width, img_height))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = x / 255\n",
    "        pred = np.argmax(model.predict(x)[0])\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(classes.index(img_data.split('/')[-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './data/cifar100/test/*'\n",
    "img_dir = glob.glob(img_path)\n",
    "all_img = []\n",
    "for class_dir in sorted(img_dir):\n",
    "    class_images = glob.glob(class_dir+\"/*\")\n",
    "    for img_data in class_images:\n",
    "        all_img.append(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全かくれ層の全出力を保存\n",
    "layer_num = 1\n",
    "for layer in model.layers:\n",
    "    w_file = \"./results/cifar100/resnet50/hidden_weight_data_bn/\" + \"bn_layer_\" + str(layer_num)\n",
    "    \n",
    "    if \"batch_nor\" not in str(layer):\n",
    "        continue\n",
    "    print(layer_num, layer)\n",
    "    \n",
    "    hidden_layer_model = Model(inputs=model.input,\n",
    "                                     outputs=layer.output)\n",
    "    hidden_w = []\n",
    "    \n",
    "    for class_dir in sorted(img_dir):\n",
    "        class_images = glob.glob(class_dir+\"/*\")\n",
    "        for img_data in class_images:\n",
    "            img = image.load_img(img_data, target_size=(img_width, img_height))\n",
    "            temp_x = image.img_to_array(img)\n",
    "            temp_x = np.expand_dims(temp_x, axis=0)\n",
    "            temp = hidden_layer_model.predict(temp_x)\n",
    "            hidden_w.append(temp)\n",
    "    \n",
    "    np.save(w_file, hidden_w)\n",
    "    layer_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
